{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Packages and start clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import base64\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "import httpx\n",
    "import json\n",
    "import re\n",
    "from config import ANTHROPIC_API_KEY, OPENAI_API_KEY\n",
    "\n",
    "openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "anthropic_client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load files and create dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carpeta con las imágenes de las preguntas\n",
    "image_folder = \"tests/mat-m1/questions-images\"\n",
    "\n",
    "# Archivo CSV con las respuestas correctas\n",
    "csv_file = \"tests/mat-m1/answers.csv\"\n",
    "\n",
    "# Diccionarios para almacenar los resultados de cada modelo de IA\n",
    "openai_answers = {}\n",
    "openai_results = {}\n",
    "anthropic_answers = {}\n",
    "\n",
    "# Read the CSV file and store the correct answers in a dictionary. Skip first row (header)\n",
    "correct_answers = {}\n",
    "with open(csv_file, \"r\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        question_number, correct_answer = row\n",
    "        correct_answers[question_number] = correct_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparar el prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Eres un experto en matemáticas. Mira detenidamente la imagen y dime cuál es la alternativa correcta. Asegúrate de no caer en alternativas distractoras (aquellas que se ven correctas pero no lo son). Resuelve esto paso a paso para asegurarte de que tienes la respuesta correcta. Cuando tengas la respuesta correcta, escríbela entre &&&. Por ejemplo, si la respuesta es la alternativa E, escribe 'La alternativa correcta es &&&E&&&'.\"\n",
    "\n",
    "# Save JSON safe prompt\n",
    "prompt = json.dumps(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Give images to OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Loop through each correct answer, only the first 5 items\n",
    "for question_number, correct_answer in list(correct_answers.items()):\n",
    "    # Get the image path\n",
    "    image_path = os.path.join(image_folder, f\"{question_number}.png\")\n",
    "\n",
    "    # Getting the base64 string\n",
    "    base64_image = encode_image(image_path) \n",
    "\n",
    "    # Send the image to OpenAI Vision API\n",
    "    openai_response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-4-vision-preview\",\n",
    "    messages=[\n",
    "        {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": f\"{prompt}\"},\n",
    "            {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "            },\n",
    "            },\n",
    "        ],\n",
    "        }\n",
    "    ]\n",
    "    )\n",
    "    response = str(openai_response.choices[0].message.content)\n",
    "\n",
    "    # Find first ocurrence of &&& in the response using find()\n",
    "    start = response.find(\"&&&\")\n",
    "\n",
    "    # Get the next character after the first &&&\n",
    "    openai_answer = response[start+3]\n",
    "    \n",
    "    # Compare the answers with the correct answer\n",
    "    openai_answers[question_number] = openai_answer \n",
    "\n",
    "    openai_results[question_number] = openai_answer == correct_answer\n",
    "\n",
    "# Save openai_results and openai_answers to a csv\n",
    "with open(\"openai_results.csv\", \"w\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Question\", \"Answer\", \"Correct\"])\n",
    "    for question, answer in openai_answers.items():\n",
    "        writer.writerow([question, answer, openai_results[question]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each correct answer\n",
    "for question_number, correct_answer in correct_answers.items():\n",
    "    # Get the image path\n",
    "    image_path = os.path.join(image_folder, f\"{question_number}.png\")\n",
    "\n",
    "    # Send the image to OpenAI Vision API\n",
    "    response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-4-vision-preview\",\n",
    "    messages=[\n",
    "        {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"What’s in this image?\"},\n",
    "            {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n",
    "            },\n",
    "            },\n",
    "        ],\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=300,\n",
    "    )\n",
    "    openai_answer = response[\"output\"][\"label\"]\n",
    "\n",
    "    # Send the image to Claude API of Anthropic\n",
    "    with open(image_path, \"rb\") as file:\n",
    "        image_base64 = base64.b64encode(file.read()).decode(\"utf-8\")\n",
    "    response = anthropic_client.image.create(\n",
    "        image=image_base64,\n",
    "        model=\"claude-vision-model-id\"\n",
    "    )\n",
    "    anthropic_answer = response[\"choices\"][0][\"text\"].strip()\n",
    "\n",
    "    # Compare the answers with the correct answer\n",
    "    openai_results[question_number] = openai_answer == correct_answer\n",
    "    anthropic_results[question_number] = anthropic_answer == correct_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesar cada imagen de pregunta\n",
    "for image_file in os.listdir(image_folder):\n",
    "    image_path = os.path.join(image_folder, image_file)\n",
    "    question_number = os.path.splitext(image_file)[0]  # Obtener el número de pregunta del nombre del archivo\n",
    "\n",
    "    # Enviar la imagen a OpenAI Vision API\n",
    "    response = openai.Image.create(\n",
    "        file=image_path,\n",
    "        model=\"image-classifier-v3\"\n",
    "    )\n",
    "\n",
    "    # Enviar la imagen a Claude API de Anthropic\n",
    "    response = anthropic.Image.create(\n",
    "        image=image_path,\n",
    "        model=\"claude-vision-model-id\"\n",
    "    )\n",
    "    anthropic_answer = response[\"choices\"][0][\"text\"].strip()  # Obtener la respuesta de Claude\n",
    "\n",
    "    # Comparar las respuestas con la respuesta correcta\n",
    "    correct_answer = correct_answers[question_number]\n",
    "    openai_results[question_number] = openai_answer == correct_answer\n",
    "    anthropic_results[question_number] = anthropic_answer == correct_answer\n",
    "\n",
    "# Calcular el rendimiento de cada modelo de IA\n",
    "openai_correct = sum(openai_results.values())\n",
    "openai_total = len(openai_results)\n",
    "openai_accuracy = openai_correct / openai_total\n",
    "\n",
    "anthropic_correct = sum(anthropic_results.values())\n",
    "anthropic_total = len(anthropic_results)\n",
    "anthropic_accuracy = anthropic_correct / anthropic_total\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"OpenAI Vision API:\")\n",
    "print(f\"Correctas: {openai_correct}/{openai_total}\")\n",
    "print(f\"Precisión: {openai_accuracy:.2%}\")\n",
    "\n",
    "print(\"Anthropic Claude API:\")\n",
    "print(f\"Correctas: {anthropic_correct}/{anthropic_total}\")\n",
    "print(f\"Precisión: {anthropic_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1_url = \"https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg\"\n",
    "image1_media_type = \"image/jpeg\"\n",
    "image1_data = base64.b64encode(httpx.get(image1_url).content).decode(\"utf-8\")\n",
    "\n",
    "message = anthropic_client.messages.create(\n",
    "    model=\"claude-3-opus-20240229\",\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image\",\n",
    "                    \"source\": {\n",
    "                        \"type\": \"base64\",\n",
    "                        \"media_type\": image1_media_type,\n",
    "                        \"data\": image1_data,\n",
    "                    },\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Describe this image.\"\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai_client.chat.completions.create(\n",
    "  model=\"gpt-4-vision-preview\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"What’s in this image?\"},\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n",
    "          },\n",
    "        },\n",
    "      ],\n",
    "    }\n",
    "  ],\n",
    "  max_tokens=300,\n",
    ")\n",
    "\n",
    "print(response.choices[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
